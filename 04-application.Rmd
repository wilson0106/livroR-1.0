# Teste-t.


Ao iniciarmos nossos estudos geralmente estamos interessados em saber se alguma característica da população que coletamos e analisamos é similar a uma outra população. Podemos abordar essa ideia por diversos caminhos porém vamos iniciar nossas análises em R através do teste-t para uma amostra e a discussão sobre hipótese nula, caudalidade e nível de confiança. A partir de então seguiremos para o teste-t com duas amostras e o teste-t pareado.


## Teste-t para uma amostra


Conduzimos esse teste quando objetivamos verificar se a média de uma dada variável é similar a um valor esperado. Ao falarmos de média percebemos que a variável com a qual estamos lidando é do tipo númerica ou inteiro (a diferença entre ambas consiste na presença de casas decimais), ou seja, quantitativo. Ao compararmos a média de nossa variável a um valor previamente estipulado 2 hipóteses são construídas, a hipótese nula (H0) e a hipótese alternativa (HA). H0 diz que a média de nossa variável é similar ao valor previamente estipulado, enquanto que HA diz que a média de nossa variável é diferente do valor previamente estipulado.


Matematicamente podemos obter o resultado do teste-t pela seguinte fórmula: $t_s=(x-mi)/(s/sqrt(n))$. Onde, x: média da amostra, mi: média teórica esperada, s: desvio padrão da amostra, n: tamanho da amostra.


Vamos verificar como conduzir esse teste no R por meio de exemplos utilizando valores fictícios.


Imagine o seguinte exemplo: 100 camarões foram coletados em um estuário. Suas medidas em relação ao tamanho foram tomadas e deseja-se saber se o seu tamanho médio é similar ou não ao tamanho médio (25,80 mm) da mesma espécie observada em outro estuario.


A partir do exemplo acima podemos definir nossas hipóteses, onde.

H0: média observada igual à média esperada;

HA: média observada diferente da média esperada;


Vamos começar gerando os dados relativos ao tamanho observado dos camarões que coletamos


```{r}
set.seed(1234)
tamanho.camarao <- rnorm(n = 100) + runif(n = 100, min = 17, max = 33)
```


A função *set.seed()* define os números aleatórios que serão gerados. Dessa forma, quando aplicado essa função associada a um número comum, no caso "1234", os números gerados aqui serão os mesmos em qualquer lugar.


A nossa segunda linha de comando utiliza a função *rnorm()* o qual gera números aleatórios considerando uma distribuição normal e soma esses valores gerados a uma distribuição uniforme gerada pela função *runif()*. A estas funções adicionamos argumentos que definem a quantidade de números gerados (argumento "n"), o valor mínimo que pode ser gerado (argumento "min") e o valor máximo que pode ser gerado (argumento "max"). E guardamos o resultado obtido em um objeto chamado tamanho.camarao. Repare que o nome do objeto não apresenta espaços ou acentos, que pode gerar problemas e/ou dificuldades na condução das análises.


Vamos verificar o resultado. Basta digitarmos o nome do objeto.


```{r}
tamanho.camarao
```



Vamos observar as métricas e gráficos, conforme já fizemos nos capítulos anteriores, mas relativos ao objeto criado.


```{r hist-tam-cam, fig.cap = "Histograma dos valores do objeto relativo ao tamanho dos camarões"}
mean(tamanho.camarao)
min(tamanho.camarao)
max(tamanho.camarao)
length(tamanho.camarao)
hist(tamanho.camarao)
```


Como podemos ver os valores mínimo e máximo são similares ao que definimos e o número de elementos é o mesmo. Graficamente podemos ver que a distribuição é normal, pois como vimos utilizamos uma função que cria uma distribuição normal com limites definidos pela função *runif()*. Além disso vemos que há uma maior frequência dos valores em torno de 25 (Figura \@ref(fig:hist-tam-cam)).


Vamos verificar, agora se esse valor que geramos (obtivemos de tamanho do camarão) são similares ao observado em outra localidade, por meio do teste-t para uma amostra.


```{r}
esperado = 25.80
t.test(x = tamanho.camarao, mu = esperado)
```



Dois comandos foram executados, no primeiro criamos um objeto, denominado "esperado", que guarda o valor referente ao tamanho de camarão observado em outro estuário (25,80 mm). O segundo comando que realizamos refere-se a função do teste-t no qual inserimos 2 argumentos. O primeiro argumento (x) refere-se ao nosso objeto que contem os dados referentes ao tamanho que coletamos e o segundo argumento (mu) refere-se ao objeto que contem a média do tamanho obtido em outro estuário.


Conforme podemos visualizar no resultado temos 9 linhas. A primeira linha nos diz qual teste está sendo conduzido, neste caso é ("One Sample t-test" ou teste-t par auma amostra), a segunda linha nos retorna o conjunto de dados que utilizamos, a terceira linha nos retorna o valor do teste t (t = -2,2432) o grau de liberdade (df = 99) e o valor de probabilidade associado ao teste (p-value = 0,02711), a quarta linha nos retorna qual é nossa hipótese alternativa, caso a aceitemos (a qual nos diz que: a média dos nossos dados não é igual à 25,8), a quinta e sexta linhas nos fornece o intervalo de confiança de 95% dos nossos dados (24,03263 e 25,69173) e da sétima a nona linha refere-se a informação relativa a média dos nossos dados (24,86218).


Em resumo, podemos inferir que a média dos nossos dados é diferente do valor esperado pois o p-value foi menor que 0,05. Além disso podemos dizer que a média do tamanho dos camarões que coletamos (24,86 mm) é estatisticamente menor do que a média presente no outro estuário (25,80 mm). De outra forma podemos dizer que se rejeitarmos H0 cometeremos um erro de 1,5% (p-value em percentual), ou seja, 1,5% de estarmos cometendo o erro tipo 1 (rejeitar a H0 quando ela é verdadeira), como 1,5% é menor que 5%, temos subsídio para afirmar que a média obtida (24,86 mm) é diferente da média esperada (25,80 mm) (98,5% de certeza). 


Ok, verificamos e entendemos como conduzir a análise. Mas há um conceito estatístico importante na análise do teste-t, a caudalidade. No exemplo anterior nós trabalhamos com as hipóteses de que a média de um conjunto de dados é igual (H0) ou diferente (HA) da média esperada. O que implica em dizer que a média que observamos pode ser maior ou menor do que o esperado. Contudo em algumas instâncias podemos querer verificar se a média do nosso conjunto de dados é maior ou igual ou menor ou igual a média esperada e não diferente. Desta diferença na construção da hipótese que emerge o conceito da caudalidade. No exemplo anterior foi testado a hipótese bicaudal que é tido como padrão ("default") na função do R que executamos.


A diferença entre realizar o teste-t bicaudal ou unicaudal depende da pergunta feita previamente e dos dados coletados. Então antes de realizar este teste mantenha-se atento a hipótese que se deseja testar.


Agora imagine o seguinte exemplo: Em um costão rochoso foi observado ao longo do dia "1" 100 estrelas do mar em diferentes alturas, em relação a baixamar. Essas alturas foram quantificadas (valores serão construídos abaixo). Sabe-se que no dia anterior "0" a altura média das estrelas no mesmo costão foi de 0,90 m. Sabe-se também que o dia anterior (dia 0) foi mais frio e que dias mais frios implicam em maiores alturas. A partir dessas informações e quais são as hipóteses testadas e o resultado do teste-t.


H0: A média da altura das estrelas do mar no costão no dia "1" é menor ou igual ao dia "0"

HA: A média da altura das estrelas do mar no costão no dia "1" é maior que a do dia "0"


Matematicamente podemos escrever da seguinte forma:


H0: μ ≤ 0,90

HA: μ > 0,90


```{r}
set.seed(1234)
estrelas <- rnorm(n = 100, sd = 0.02) + runif(n = 100, min = 0.4, max = 1.3)
```


Observe que geramos os dados de maneira similar ao que fizemos no exemplo anterior (inserindo os valores das alturas das estrelas em um objeto chamado estrelas), a diferença é que inserimos um argumento na função *rnorm()* que corresponde ao desvio padrão (de 0,02) dos dados normais que estamos gerando.


```{r estrelas-hist, fig.cap = "Histograma dos valores relativos a altura das estrelas do mar no costão rochoso"}
mean(estrelas)
min(estrelas)
max(estrelas)
length(estrelas)
hist(estrelas)
```


Conforme também fizemos anteriormente calculamos algumas métricas para entender os dados e um histograma básico (Figura \@ref(fig:estrelas-hist)) para visualizar a forma dos dados que representam a altura que as estrelas se encontram no ambiente.


```{r}
dia.0 = 0.90
t.test(x = estrelas, mu = dia.0, alternative = "greater")
```


Agora construímos um objeto chamado "dia.0" que nos retorna o valor médio encontrado para altura das estrelas do mar no costão no dia 0 e seguimos com o teste-t onde avaliamos se os dados que obtivemos do dia 1 são menores ou iguais ao dia 0, por meio do argumento "alternative" definido-o como "greater". Este argumento novo que incluímos pode ser definido de 3 formas: "two-sided" que é o padrão ("default"), "greater" ou "less". O argumento "alternative" seguirá o sinal da hipótese alternativa que foi construída para o teste.


Com isso podemos avaliar o resultado que é similar ao que vimos anteriormente com poucas mudanças. A primeira linha (One Sample t-test) informa sobre o teste realizado. A segunda linha indica o nome do conjunto de dados que inserimos. A terceira linha nos dá o valor do teste-t (t = -2,2073), do grau de liberdade (df = 99) e da probabilidade associada ao teste (p-value = 0.9852). A quarta linha indica a hipótese alternativa, caso seja aceita (o que não é o caso), que é verdade que a média dos nossos dados são maiores que 0,90 m. A quinta e sexta linha indicam o intervalo de confiança de 95% dos nossos dados (0,8087617 e inf). A sétima, oitava e nona linha referem-se a média dos dados.


Como podemos notar pelo p-value do nosso resultado este demonstra que não temos informação o suficiente para rejeitar nossa hipótese nula (H0). Portanto a média dos nossos dados é menor ou igual a 0,90.


Outro conceito importante de qualquer teste inferencial (ex. teste-t) é o nível de confiança. Até o presente momento consideramos o nível de confiança de 95%. Se quisermos altera-lo no teste-t devemos adicionar o argumento "conf.level" em proporção (0-1). A sua alteração implica na alteração da zona de rejeição da hipótese nula. Se aumentarmos o seu valor fica mais dificil rejeitarmos a hipótese nula e se diminuirmos o seu valor fica mais fácil rejeitar a hipótese nula. Vejamos outro exemplo.


Imagine o seguinte exemplo: Um pesquisador avaliou o tamanho de cracas incrustados no casco de uma embarcação. Objetivando saber se o tamanho médio de cracas difere do teórico esperado (20 mm) um teste-t bicaudal foi aplicado a um nível de confiança de 95% e 99%.


Vamos descrever as hipóteses e realizar a análise para ambos os níveis de confiança.


Neste caso temos as seguintes hipóteses:

H0: O tamanho médio observado é similar ao teórico

HA: O tamanho médio observado difere do teórico


Conforme já realizado anteriormente vamos gerar os dados e explora-los com algumas métricas estatśticas e gráficas de maneira similar ao que fizemos no exemplo anterior.


```{r craca-hist, fig.cap = "Histograma dos valores relativos ao tambanho das cracas incrustantes"}
set.seed(1234)
cracas <- rnorm(n = 100, sd = 1.9) + runif(n = 100, min = 5, max = 25)

mean(cracas)
min(cracas)
max(cracas)
length(cracas)
hist(cracas)
```


Agora que visualizamos as métricas e graficamos os dados (Figura \@ref(fig:craca-hist)), sigamos com a condução da análise.


```{r}
teorico <- 13.5
t.test(x = cracas, mu = teorico, conf.level = 0.95)
t.test(x = cracas, mu = teorico, conf.level = 0.99)
```


Como podem ver ambos os resultados (com diferentes níveis de confiança) retornam o mesmo valor do teste-t e do "p-value". E neste ponto precisamos ir com calma para evitar erro de interpretação do resultado e entender estatisticamente o que está acontencendo.


Quando representamos o nível de confiança (representado pelo argumento "conf.level") por um valor probabilístico de 0,95 ou 0,99 estamos dizendo que o nível de significância é 0,05 e 0,01, respectivamente. Quando olhamos para o resultado do p-value, temos que levar em consideração o nível de significância (que consiste em: 1 - nível de confiança). 


Vejamos o nosso resultado. 


No primeiro caso ("conf.level = 0.95") temos p-value = 0.02289, como este valor é menor que 0,05 (nosso nível de significância), isso quer dizer que a média teórica está fora do intervalo de confiança dos dados, portanto rejeitamos a hipótese nula.


No segundo caso ("conf.level = 0.99") temos o mesmo "p-value", contudo este valor é maior que nosso nível de significância (0,01), isso quer dizer que nossa média teórica está dentro do intervalo de confiança, portanto aceitamos a hipótese nula de que a média observada é similar a média teórica.


O nível de significância a aplicar nos seus dados depende das informações que possui sobre o organismo e o ambiente que está estudando. Apesar da regra-de-bolso dizer 0,05 e por padrão o R definir esse nível de significância é necessário discutir o que ele representa para seus dados e qual a implicação para sua hipótese e as medidas que serão tomadas. Uma dica importante é: reporte sempre o intervalo de confiança, indique o nível de significância (consiste em: 1 menos o nível de confiança) que foi aplicado e no seu texto deixe claro a escolha do nível de significância, principalmente se for diferente do que é definido como padrão. 


**BÔNUS:**


Embora não seja comum, podemos plotar um gráfico que represente o nosso resultado estatístico como uma curva de densidade no qual é representado o valor do teste-t, o grau de liberdade e o valor de probabilidade associado. Para isso vamos usar um pacote o qual precisa ser instalado chamado "webr" e precisamos carrega-lo usando a função library(). Após isso é só inserir a função que desenvolve o teste-t dentro da função plot(). Veja o resultado para ambos os níveis de confiança estabelecidos previamente. OBS: Uma vez instalado o pacote não precisa instala-lo novamente.


```{r, eval = -1}
install.packages("webr")
library(webr)
```


```{r cracas-dens-95, fig.cap = "Curva de densidade representando o valor do teste-t bicaudal para o tamanho das cracas em relação a média teórica a um intervalo de confiança de 95%. O ponto azul indica o valor do teste."}
plot(t.test(x = cracas, mu = teorico, conf.level = 0.95))
```

```{r cracas-dens-99, fig.cap = "Curva de densidade representando o valor do teste-t bicaudal para o tamanho das cracas em relação a média teórica a um intervalo de confiança de 99%. O ponto azul indica o valor do teste."}
plot(t.test(x = cracas, mu = teorico, conf.level = 0.99))

```


Verifique que esses plots nos fornecem as curvas do teste-t aos intervaloe de confiança de 95% (Figura \@ref(fig:cracas-dens-95)) e 99% (Figura \@ref(fig:cracas-dens-99)), demarca os limites inferior e superior de vermelho e marca como ponto azul na curva de densidade o valor do teste-t associado. Como esse valor está dentro da região demarcada no intervalo de confiança de 95%, neste caso rejeitamos a hipótese nula e como no intervalo de confiança de 99% o ponto azul está fora da região demarcada aceitamos a hipótese nula.


## Teste-t para duas amostras


Conduzimos esse teste quando objetivamos comparar se a média de dois grupos (= amostras, populações etc) são similares. Portanto para sua realização é necessário uma variável mensurável e uma variável categórica com 2 grupos.


Ou seja, partindo desse objetivo as hipóteses nula e alternativa desse teste são as seguintes:

H0: A diferença na média da variável quantitativa dos grupos é igual a 0;

HA: A diferença na média da variável quantitativa dos grupos é diferente de 0;


Outra forma de apresentarmos a hipótese relativa a esste teste é:

H0: A média da variável quantitativa é igual entre grupos;

HA: A média da variável quantitativa é diferente entre grupos;


Outra forma de escrevermos a hipótese é em relação a caudalidade do teste e, se unicaudal, pode ser escrita da seguinte forma:

H0: A média da variável quantitativa é maior ou igual (ou menor ou igual) entre grupos;

HA: A média da variável quantitativa é menor (ou maior) entre grupos;


A partir desse teste alguns pressupostos estatísticos precisam ser avaliados e portanto algumas análises precisam ser realizadas antes da interpretação do resultado do teste-t. Pressupostos como normalidade (ambos os grupos devem provir de uma população com distribuição normal) e homocedasticidade (A variância entre os dois grupos devem ser iguais). Demonstraremos a frente como realizar alguns desses testes. Mas, primeiro vamos gerar os dados a serem trabalhados para esta etapa. Execute o código abaixo e você irá visualizar no "environment" do seu RStudio um objeto chamado "gastropode" que corresponde a um data frame com o conjunto de dados que iremos trabalhar.


```{r}
grupos <- c(rep(x = "Alimento A", 50), rep(x = "Alimento B", 50))
set.seed(123)
alimento.A <- rnorm(n = 50, mean = 0.7, sd = 0.2)
set.seed(4321)
alimento.B <- rnorm(n = 50, mean = 0.2, sd = 0.2)
Alimento <- c(alimento.A, alimento.B)
gastropode <- as.data.frame(cbind(grupos, round(Alimento, 3)))
colnames(gastropode) <- c("Alimento", "Peso")
rm(list = "grupos", "alimento.A", "alimento.B", "Alimento")
```


`r colorize("Neste momento não entraremos em detalhes sobre os comandos aplicados para construção desses dados. Caso seja do seu interesse consulte o apêndice, no final do livro.", "red")`


Vamos, agora, verificar os dados por meio da função *head()* e a estrutura dos dados por meio da função *str()* e alterar a estrutura dos dados se necessário.


```{r}
head(gastropode)
str(gastropode)

gastropode$Alimento <- as.factor(gastropode$Alimento)
gastropode$Peso <- as.numeric(gastropode$Peso)
str(gastropode)
```



Agora que importamos e organizamos nossa planilha vamos analisar nosso exemplo.


100 indivíduos de uma espécie de gastropode foi coletada e mantida em cultivo para avaliação da dieta. 50 indivíduos foram mantidos com uma dieta rica no Alimento A e 50 indivíduos com uma dieta rica no Alimento B. Todos os indivíduos foram pesados antes e depois do experimento. A planilha a seguir informa a alteração de peso dos organismos, em gramas, após a dieta oferecida.


Antes de conduzirmos o teste-t vamos praticar fazendo a avaliação gráfica e númerica dos dados.


```{r hist-ali-A, fig.cap = "Histograma com valores da mudança do peso dos gastrópodes após a dieta com o Alimento A"}
hist(gastropode$Peso [gastropode$Alimento == "Alimento A"], 
     xlab = "Alteração do peso", 
     ylab = "Frequência", 
     main = "Alimento A", 
     ylim = c(0, 20),
     xlim = c(-0.5, 1.5))
```


```{r hist-ali-B, fig.cap = "Histograma com valores da mudança do peso dos gastrópodes após a dieta com o Alimento B"}
hist(gastropode$Peso [gastropode$Alimento == "Alimento B"], 
     xlab = "Alteração do peso", 
     ylab = "Frequência", 
     main = "Alimento B",
     ylim = c(0, 20),
     xlim = c(-0.5, 1.5))
```

```{r box-ali, fig.cap = "Boxplot com os valores da alteração do peso dos gastrópodes por tipo de alimento"}
boxplot(Peso ~ Alimento, data = gastropode)
```


Os comandos acima realizam: o histograma dos dados para Alimento A (Figura \@ref(fig:hist-ali-A)), o histograma dos dados para Alimento B (Figura \@ref(fig:hist-ali-B)) e o boxplot para ambos os dados (Figura \@ref(fig:box-ali)), respectivamente.


Os 2 primeiros gráficos consistem em histogramas em relação aos dados de peso por Alimento. Na primeira linha indicamos a variável peso dentro da planilha gastropode por meio do operador matemático $ (cifrão) e selecionamos os dados correspondentes ao Alimento utilizando colchetes [] dentro do qual selecionamos a variável Alimento dentro da planilha gastropode e por meio do sinal de igual duplicado (==) indicamos entre aspas ("") o grupo (ou categoria) que desejamos. Os demais argumentos já são bem conhecidos e iguais para ambos os histogramas, diferindo apenas o título do gráfico que é definido pelo argumento "main".


O Boxplot resume os dados por Alimento e nos indica outras métricas (quartis), como vimos anteriormente no tópico sobre gráficos.


Mas se desejarmos observar os valores númericos que resumem os dados, podemos seguir o que aprendemos anteriormente.


```{r}
summary(gastropode)

mean(gastropode$Peso)
mean(gastropode$Peso [gastropode$Alimento == "Alimento A"])
mean(gastropode$Peso [gastropode$Alimento == "Alimento B"])
```


Utilizando o pacote Rmisc temos uma forma mais simples de escrita e eficiente para observar esses valores e algumas outras métricas (ex.: número amostral, média, desvio padrão, erro padrão e intervalo de confiança).


```{r}
library(Rmisc)
summarySE(data = gastropode, measurevar = "Peso", groupvars = "Alimento")
```


Ok, até aqui observamos como estão os nossos dados e podemos ver que a administração da Alimento A resultou em um maior ganho de peso pelos gastropodes do que a Alimento B. Mas será que o que observamos grafica e numericamente se reflete estatisticamente? Vamos a nossa avaliação dos pressupostos do teste-t para duas amostras e se cumpridos para a avaliação do teste-t.


Uma das formas mais convencionais de avaliar a normalidade é pelo teste de shapiro-wilks e a homocedasticidade pelo teste de Bartlett. Vamos avalia-las.


```{r}
shapiro.test(gastropode$Peso [gastropode$Alimento == "Alimento A"])
shapiro.test(gastropode$Peso [gastropode$Alimento == "Alimento B"])

bartlett.test(Peso ~ Alimento, data = gastropode)
```


Como podemos observar, ambos os grupos apresentam dados normais e homocedásticos, para um nível de confiança de 95%, já que o p-value foi superior a 0,05. Dessa forma vamos dar continuidade a nossa análise e verificar se as médias dos grupos são diferentes.


```{r}
t.test(Peso ~ Alimento, 
       data = gastropode,
       var.equal = TRUE,
       conf.level = 0.95)
```


Repare que a forma da escrita se alterou um pouco. Mas como podem ver, nada complicado. Agora escrevemos a variável quantitativa (peso) em função da (~) variável categórica (Alimento). Guarde bem essa forma de escrita pois ela será utilizada para praticamente todos os testes a partir daqui e para inúmeras outras funções. Adcionamos o argumento "data" que indica a planilha de onde estamos utilizando as variáveis, o argumento "var.equal" o qual indica que a variância entre os grupos é igual e o argumento "conf.level" o qual define o nível de confiança com qual estamos trabalhando.


De acordo com nosso resultado podemos ver que o o valor do teste-t é 14,065, o grau de liberdade de 98 (o qual consiste no total de observações subtraído de um por grupo), o valor de probabilidade associado ao teste ($2,2\times10^{-16}$), o intervalo de confiança de 95% (0,415 e 0,551) que refere-se a diferença da média entre os grupos (a diferença da média dos grupos é: 0,70690 - 0,22348 = 0,48342), ou seja, o intervalo de confiança é em função dessa diferença e as últimas linhas do resultado representam as médias de alteração do peso para cada Alimento (Alimento A = 0,70690 e Alimento B = 0,22348). De acordo com esse resultado refutamos a hipótese nula de que as médias são similares. Portanto podemos dizer que dependendo da Alimento (A ou B) utilizada na dieta podemos ter diferentes alterações no peso dos gastropodes.


Da mesma forma que avaliamos para o teste-t de uma amostra, podemos plotar o resultado como um gráfico da função de densidade do teste-t. Só devemos lembrar de carregar o pacote "webr".


```{r testet-duas-dens, fig.cap = "Curva de densidade representando o valor do teste-t bicaudal para a alteração do peso de gastrópodes em relação ao alimento a um intervalo de confiança de 95%. O ponto azul indica o valor do teste."}
library(webr)
plot(t.test(Peso ~ Alimento, 
            data = gastropode,
            var.equal = TRUE,
            conf.level = 0.95))
```


Neste gráfico podemos ver que o resultado do teste-t (Figura \@ref(fig:testet-duas-dens)), indicado pelo ponto azul, está muito além do nível da zona de rejeição, indicando que os dois grupos apresentam médias bem diferentes, ou seja, a diferença entre as duas médias é altamente significativa e diferente de 0.


Vamos exercitar nosso conhecimento em R e teste-t com um outro exemplo (Gere a planilha abaixo).


```{r}
grupos <- c(rep(x = "Ano 0", 36), rep(x = "Ano 20", 36))
set.seed(245)
ano.0 <- rnorm(n = 36, mean = 15.7, sd = 0.2) + runif(n = 36)
set.seed(356)
ano.20 <- rnorm(n = 36, mean = 16.2, sd = 0.5) + runif(n = 36)
ano <- c(ano.0, ano.20)
lagoa <- as.data.frame(cbind(grupos, round(ano, 3)))
colnames(lagoa) <- c("Ano", "Temperatura")
rm(list = "grupos", "ano.0", "ano.20", "ano")
```


Imagine que durante um ano você mensurou a temperatura de uma lagoa três vezes por mês durante todos os meses ao longo de 1 ano. 20 anos depois você retornou a lagoa e mensurou novamente a temperatura três vezes por mês durante um ano. Considerando um nível de confiança de 99% a temperatura é igual ou diferente entre os anos?


A primeira coisa que devemos fazer é escrever nossa hipótese. Vamos a ela.

H0: A média da temperatura é igual entre os anos;

HA: A média da temperatura é diferente entre os anos;


Com a hipótese construída vamos verificar a estrutura dos dados (modificar se necessário) e sumarizar nossos dados gráfica e matematicamente.


```{r}
head(lagoa)
str(lagoa)

lagoa$Ano <- as.factor(lagoa$Ano)
lagoa$Temperatura <- as.numeric(lagoa$Temperatura)
str(lagoa)
```

```{r hist-temp-0, fig.cap = "Histograma com valores de temperatura da lagoa no Ano 0."}
hist(lagoa$Temperatura [lagoa$Ano == "Ano 0"], 
     xlab = "Temperatura (°C)", 
     ylab = "Frequência", 
     main = "Ano 0", 
     ylim = c(0, 15),
     xlim = c(15, 19))
```

```{r hist-temp-20, fig.cap = "Histograma com valores de temperatura da lagoa no Ano 20."}
hist(lagoa$Temperatura [lagoa$Ano == "Ano 20"], 
     xlab = "Temperatura (°C)", 
     ylab = "Frequência", 
     main = "Ano 20", 
     ylim = c(0, 15),
     xlim = c(15, 19))
```

```{r box-temp, fig.cap = "Boxplot com os valores de temperatura da lagoa por ano."}
boxplot(Temperatura ~ Ano, data = lagoa)
```


Como podem verificar os comandos para a análise gráfica não diferiu do que fizemos no exemplo anterior. Os comandos acima realizam: o histograma dos valores de temperatura no ano 0 (Figura \@ref(fig:hist-temp-0)), o histograma dos valores de temperatura no ano 0 (Figura \@ref(fig:hist-temp-20)) e o boxplot para ambos os dados (Figura \@ref(fig:box-temp)), respectivamente. Quanto ao seu resultado podemos notar uma maior temperatura média anual da lagoa 20 anos depois da primeira amostragem.


```{r}
summary(lagoa)

library(Rmisc)
summarySE(data = lagoa, measurevar = "Temperatura", groupvars = "Ano")
```


Aplicando a função *summarySE()* do pacote Rmisc obtivemos sumarizamos nossos dados como mostrado acima e em relação aos valores de média e desvios podemos observar que a média é bem próxima, mas será que elas são estatisticamente iguais? Para isso vamos realizar o teste-t.


Antes do teste vamos calcular os pressupostos do teste, normalidade e homocedasticidade.


```{r}
shapiro.test(lagoa$Temperatura [lagoa$Ano == "Ano 0"])
shapiro.test(lagoa$Temperatura [lagoa$Ano == "Ano 20"])

bartlett.test(Temperatura ~ Ano, data = lagoa)
```


Como podemos ver os dados são normais, porém não são homocedasticos (a variância não é igual entre os grupos). Neste caso podemos fazer um teste-t de Welch (este teste aplica uma correção quando as variâncias não são iguais). Contudo, o teste de Welch ele é comumente usado quando o N amostral é considerado baixo (menor que 10 para um dos dois grupos). Vamos Analisar o teste-t considerando a variância igual e desigual para ver se há diferença significativa no resultado do teste ou não.


```{r}
t.test(Temperatura ~ Ano, 
       data = lagoa,
       var.equal = TRUE,
       conf.level = 0.99)

t.test(Temperatura ~ Ano, 
       data = lagoa,
       var.equal = FALSE,
       conf.level = 0.99)
```


Como podem notar a forma de escrever o teste é similar ao exemplo anterior as alterações consistem nas variáveis e conjunto de dados utilizado e como foi pedido no teste a alteração do nível de confiança para 99% (conf.level = 0,99) e os dois teste-t (com variância igual e com variância desigual - Welch).


Olhando para os dois resultados ambos os testes demonstraram diferenças significativas entre os anos, pois o p-value foi menor que 0,01 (lembrar que como o nível de confiança foi alterado para 0,99 a significância só ocorrerá se o p-value for menor que 0,01, como é o caso). Porém podemos ver que não há muita diferença em relação aos valores de ambos os teste-t, pois como comunicamos a aplicação do teste-t de Welch apresenta maior importância quando as variâncias são desiguais e o número amostral de um dos grupos é muito pequeno.


Assim como fizemos anteriormente vamos olhar o resultado em relação a distribuição da função de densidade do teste-t para um nível de confiança de 99% (Figura \@ref(fig:testet-duas-temp-dens)). Só devemos lembrar de carregar o pacote "webr" se ainda não foi carregado.


```{r testet-duas-temp-dens, fig.cap = "Curva de densidade representando o valor do teste-t bicaudal para comparação da temperatura em um lago entre dois anos a um intervalo de confiança de 99%. O ponto azul indica o valor do teste."}
library(webr)
plot(t.test(Temperatura ~ Ano, 
            data = lagoa,
            var.equal = TRUE,
            conf.level = 0.99))
```


De acordo com esse exemplo podemos afirmar que os anos diferem entre si e que em 20 anos a lagoa amostrada apresentou um aumento da temperatura.


## Teste-t pareado


Aplicamos este teste quando as duas amostras de uma variável categórica são independentes e desejamos verificar se elas são similares entre si. Contudo cada observação de ambas as amostras devem de alguma forma estar associadas para podermos dizer que ocorrem em pares. Neste caso as hipóteses são as seguintes:


H0: Não há diferença entre os pares de observações;

HA: Há diferença entre os pares de observações;


Matematicamente pode ser dita da seguinte forma:

H0: A diferença na média dos pares de observações é igual a 0;

HA: A diferença na média dos pares de observações é diferente de 0;


Vejamos um exemplo de como conduzir essa análise no R


Imagine que dois pesquisadores embarcaram com objetivo de fazer contagem de aves em alto mar. Após 20 dias de observações independentes entre os observadores obtivemos os dados abaixo.


Começaremos gerando os dados e a modificando se necessário.


```{r}
observadores <- c(rep(x = "Observador 1", 20), rep(x = "Observador 2", 20))
set.seed(2328)
aves.1 <- rnorm(n = 20, mean = 20, sd = 1) + runif(n = 20)
set.seed(3230)
aves.2 <- rnorm(n = 20, mean = 21, sd = 2) + runif(n = 20)
dia <- c("Dia 1", "Dia 2", "Dia 3", "Dia 4", "Dia 5", "Dia 6", "Dia 7", "Dia 8", "Dia 9", "Dia 10", "Dia 11", "Dia 12", "Dia 13", "Dia 14", "Dia 15", "Dia 16", "Dia 17", "Dia 18", "Dia 19", "Dia 20")
aves <- c(aves.1, aves.2)
aves <- as.data.frame(cbind(dia, round(aves.1, 0), round(aves.2, 0)))
colnames(aves) <- c("Dia", "Observador 1", "Observador 2")
rm(list = "observadores", "aves.1", "aves.2", "dia")
```

`r colorize("Neste momento não entraremos em detalhes sobre os comandos aplicados para construção desses dados. Caso seja do seu interesse consulte o apêndice, no final do livro.", "red")`


```{r}
head(aves)
str(aves)

aves$Dia <- as.factor(aves$Dia)
aves$`Observador 1` <- as.numeric(aves$`Observador 1`)
aves$`Observador 2` <- as.numeric(aves$`Observador 2`)
str(aves)
```


Agora definimos nossas hipóteses

H0: Não há diferença entre os pares de observações dos pesquisadores;

HA: Há diferença entre os pares de observações dos pesquisadores;


Vamos sumarizar os dados gráfica e estatisticamente


```{r hist-par-obs1, fig.cap = "Histograma com a frequência de observações de aves, por 20 dias, pelo observador 1"}
hist(aves$`Observador 1`, 
     xlab = "Observações", 
     ylab = "Frequência", 
     main = "Observador 1", 
     ylim = c(0, 10),
     xlim = c(18, 25))
```


```{r hist-par-obs2, fig.cap = "Histograma com a frequência de observações de aves, por 20 dias, pelo observador 2"}
hist(aves$`Observador 2`, 
     xlab = "Observações", 
     ylab = "Frequência", 
     main = "Observador 2", 
     ylim = c(0, 10),
     xlim = c(18, 25))
```


```{r box-par-ave, fig.cap = "Boxplot com as frequências de observações de aves por 20 dias de 2 observadores."}
boxplot(aves$`Observador 1`, 
        aves$`Observador 2`, 
        names = c("Observador 1", "Observador 2"),
        ylab = "Frequência de Observações")
```


Como podem verificar os comandos para a análise gráfica não diferiu do que fizemos nos exemplos anteriores para os histogramas (Figura \@ref(fig:hist-par-obs1) e \@ref(fig:hist-par-obs2)) e pouco diferiu para o boxplot ((Figura \@ref(fig:box-par-ave)).


A estrutura da planilha é diferente das anteriores o que por sua vez alterou a mudança na escrita do comando para construção para o boxplot. Desta não mais utilizamos o til (~), mas inserimos o nome da planilha seguido pelo operador matemático $ (cifrão) mais o nome da variável quantitativa que queremos representar. Inserimos também outros 2 argumentos que são "names" com dois nomes concatenados pela função c() que representam as variáveis quantitativas na ordem em que foram inseridas e o argumento "ylab" que dá nome ao eixo y.


```{r}
summary(aves)
```


Como podemos notar, devido a organização dos dados na planilha a função *summary()* já sumariza de maneira adequada nossos dados.


Em relação ao resumo dos nossos dados podemos observar que o observador 2 contabilizou um número maior de aves que o observador 1, mas será que a diferença no número de observações é nulo (0) ou é diferente. ou seja será que a média de observação entre os observadores é similar? 


O teste-t pareado não aparesenta pressuposto quanto aos dados, porém como ele avalia a diferença entre dois grupos o pressuposto requerido é a normalidade da diferença dos dados. Vamos a nossa avaliação do pressuposto.


Primeiro vamos criar um objeto que consiste na diferença entre observadores


```{r}
diferenca <- aves$`Observador 1` - aves$`Observador 2`
```


Agora vamos realizar o teste de normalidade da diferença.


```{r}
shapiro.test(diferenca)
```


De acordo com o teste de Shapiro os dados são normais. Vamos a nossa avaliação pelo teste-t


```{r}
t.test(aves$`Observador 1`,
       aves$`Observador 2`,
       paired = TRUE,
       conf.level = 0.95)
```


Para a execução do teste-t pareado 2 diferenças podem ser notadas na escrita da função. A primeira consiste no fato de que não utilizamos o til (~), mas sim as variáveis referentes as observações e a segunda é o argumento paired que tem valor lógico (ou seja, verdadeiro ou falso) e indicamos ele como "TRUE" (verdadeiro).


Quanto ao resultado podemos notar que nos é informado que o teste consiste num teste-t pareado e que a diferença entre os observadores é ligeiramente diferente a um nível de confiança de 95%, visto que o "p-value" é próximo à 0,05 e na última linha nos é indicado que a média da diferença das observações é de -1,2. Em outras palavras o teste nos diz que a média das diferenças é diferente de 0, portanto rejeitamos a hipótese nula.


Assim como fizemos anteriormente vamos olhar o resultado em relação a distribuição função de densidade do teste-t (Figura \@ref(fig:testet-par-ave)). Só devemos lembrar de carregar o pacote "webr" se ainda não foi carregado.


```{r testet-par-ave, fig.cap = "Curva de densidade representando o valor do teste-t bicaudal para comparação do número de observações de aves por 2 observadores distintos a um intervalo de confiança de 95%. O ponto azul indica o valor do teste."}
library(webr)
plot(t.test(aves$`Observador 1`,
            aves$`Observador 2`,
            paired = TRUE,
            conf.level = 0.95))
```


Neste teste em particular como trabalhamos com a diferença entre as observações vamos usar o gráfico de barras para graficar essa diferença.


```{r bar-dif-ave, fig.cap = "Diferença entre o número de observações de aves, por dia, para cada observador"}
barplot(diferenca,
        xlab = "Dias",
        ylab = "Diferença entre observadores (Observador 1 - Observador 2)",
        main = "Meu gráfico",
        names.arg = aves$Dia,
        las = 2,
        ylim = c(-7.3, 7.3),
        cex.names = 0.9)
```


Para o gráfico acima indicamos em seu comando que faremos um gráfico de barras onde o que será plotado é a diferença no número de observação de aves entre observadores (Figura \@ref(fig:bar-dif-ave)). O argumento "xlab" indica o nome do eixo x, "ylab" o nome do eixo y, "main" indica o título do gráfico, "names.arg" indica a coluna referente aos nomes das barras (que são os dias), "las" indica se os nomes das barras serão plotados na horizontal ou vertical (o valor 2 indica vertical), "ylim" indica os limites do eixo y e "cex.names" indica o tamanho da letra dos nomes das barras.


As barras para o lado positivo do eixo y indica uma maior observação de aves pelo observador 1 e as barras para baixo indicam um maior número de observações de aves pelo observador 2. Vamos indicar isso no gráfico por meio da função *mtext()* (Figura \@ref(fig:bar-dif-ave2)).


```{r bar-dif-ave2, fig.cap = "Diferença entre o número de observações de aves, por dia, para cada observador."}
barplot(diferenca,
        xlab = "Dias",
        ylab = "Diferença entre observadores (Observador 1 - Observador 2)",
        main = "Meu gráfico",
        names.arg = aves$Dia,
        las = 2,
        ylim = c(-7.3, 7.3),
        cex.names = 0.9)

mtext(at = 4,
      line = -2,
      text = "Observador 1", 
      side = 3)
mtext(at = 4, 
      line = -2,
      text = "Observador 2", 
      side = 1)
```


Como podem ver a função *mtext()* indicou os nomes Observador 1 e Observador 2 no lado do gráfico que os representa. O argumento "at" indica a posição  em relação ao eixo x, "line" indica a posição em relação ao eixo y, "text" indica o que será plotado e side indica o lado da janela gráfica onde o texto será plotado (3 é na parte superior e 1 na inferior).


asdas
